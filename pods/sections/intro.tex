%!TEX root = /Users/fgeerts/Documents/MLforloops/pods/main.tex
%With the raise of Machine Learning applications we have witnessed in recent years, there is an increasing need for languages that allow us to reason about matrix operations. 

%Matrix operations are at the very core of most Machine Learning algorithms deployed these days. Due to this, there is an increasing need to define languages allowing us to reason about matrix manipulation and more generally, about linear algebra. Several such proposals have been put forward by the database community, mostly focusing on how matrices are manipulated statically. On the other hand, many linear algebra operations require some sort of iteration or recursion. Examples of these are computing the Gaussian elimination, the inverse of a matrix, or its transitive closure.
%
%By observing that the recursion required in these algorithms amounts to repeating 
Linear algebra algorithms have become one of the key components in data analytical workflows. As such, there is growing interest in the database community to integrate linear algebra functionality in relational database management systems \cite{}. In particular, from a query language perspective, several proposals have recently been put forward to unify relational algebra and linear algebra. One such proposal is LARA~\cite{}, a minimalistic language in which a number of atomic operations on so-called associative tables are proposed. Since such tables generalize relational tables, matrices and tensors, the aimed unification of linear and relational algebra is obtained. A key operator in LARA is the extension operator, which is parametrized by (user-defined) functions. Hence, the capabilities of LARA are inherently tied to the allowed functions. Fragments of LARA are known to be expressive complete to first-order logic with aggregation~\cite{}. Furthermore, under complexity-theoretic assumptions, LARA can not compute the inverse of a matrix.\cite{}. This is primarily due to the absence of a recursion mechanism in LARA. 


Another proposal, on which we will built on, is \lang, a pure matrix query language. It consists of a number of atomic linear algebra operators, such as transpose, matrix multiplication, just to name a few. Also here there a are closed connection to first-order logic with aggregates. In fact, \lang\ is subsumed in the three-variable fragment of that logic, resulting in the inability of \lang to check for four-cliques in adjacency matrices and to compute the inverse of a matrix. Furthermore, \lang\ was recently shown to be equivalent to a restricted version of the annotated relation algebra which operates on $K$-relations, provided that input and output relations are restricted to be binary. No recursion mechanism is part of \lang.

In another line of work~\cite{}, matrices are encoded as relational tables and an extensions of SQL is proposed to carry out matrix manipulations. In particular, \cite{} extends SQL with a limited form of recursion -- alike dynamic programming - such that linear algebra-based procedures for learning feed-forward neural networks can be declaratively specified. To our knowledge, the precise expressive power of the resulting language has not been characterized. For example, it is unclear whether matrix inversion can be expressed.

Based on these works, a natural question arises: how to add a natural form of recursion to linear algebra-based query languages? Inspecting any linear algebra textbook, one sees that most linear algebra procedures heavily rely on the use of for-loops in which iterations happen over the dimensions of the matrices involved. We thus propose to extend \lang\ with limited recursion in the form of for-loops, resulting the language \langfor. To define this recursion in a natural way, we simulate a loop of the form \texttt{for i=1,...n do} by leveraging canonical vectors. In other words, we use the canonical vectors $b_1=(1,0,\ldots)$, $b_2=(0,1,\ldots)$, \ldots, to access specific rows and columns, and iterate over these vectors. As an almost direct consequence, the expressive power of \langfor goes well beyond \lang. It can check for cliques of any given size, compute the transitive closure of a graph, and as we will show, compute important linear algebra operators such as LU-decomposition, determinant, matrix inverse, among other things.

More generally, we show that \langfor\ is closely related to arithmetic circuits and we show that anything computable by an arithmetic circuit of polynomial degree can be computed in \langfor, and vice versa, provided that \langfor expressions can be compiled, in a uniform way into arithmetic circuits. Since these circuits are often said to ``capture'' linear algebra, we see our results as as a justification for our language.

Furthermore, the introduction of recursion to \lang has some interesting consequences. First of all, when consecutive iterations can only perform updates in an additive way, we show that \langfor and the annotated relation algebra are equivalent. Secondly, when iterations update in a multiplicative manner,
\langfor is equivalent to weighted logics. 



\begin{itemize}
\item Explain why this is important.
\item Say what sort of things we would like to express.
\item Give a quick tour of our minimal language (examples).
\item Stress our concrete contributions.
\item Relate to previous work \cite{matlang,BrijderGBW19,Geerts19,HutchisonHS17}.
\end{itemize}

\domagoj{A good example for the intro is all shortest paths via Floyd-Warshall.}

\noindent
$\ffor{e_k}{\Dist}{ }$
\\
\hspace*{0.5cm} $\ffor{e_i}{\Dist}{ }$
\\
\hspace*{1cm} $\ffor{e_j}{\Dist}{ }$
\\
\hspace*{1.5cm} 
$\texttt{curr} := e_i^*\cdot \Dist \cdot e_j$\\
\hspace*{1.5cm} 
$\texttt{new} := e_i^*\cdot \Dist \cdot e_k + e_k^*\cdot \Dist\cdot e_j$\\
\hspace*{1.5cm}
$\Dist + \texttt{update}(\texttt{curr},\texttt{new})\times (e_i\cdot e_j^*)$

where

\[
  			\texttt{update}(x,y)=\begin{cases}
               0, \text{ if } x<=y \\
               -x + y, \text{ if } x > y
            \end{cases}.
		\]
