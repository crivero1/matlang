When showing results based on induction of expressions in \langfor, it is convenient to assume that function applications $f(e_1,\ldots,e_k)$ for $f\in\Fun_k$ are restricted to
the case when all expressions $e_1,\ldots,e_k$ have type $1\times 1$. Furthermore, we assume that scalar multiplication is not present as an atomic operator. This does not loose generality:
%
%
% assume \langfor to have functions that process only matrices of size $1\times 1$
% and not scalar product.

\floris{I am confused by what follows below. I see that general function application can be
reduced to scalar function application. Similarly, matrix multiplication be reduced (do we use this?). BUT the expression for scalar multiplication used scalar multiplication?!?}
\begin{itemize}
\item 
For general function applications $f(e_1,\ldots,e_k)$, if we have $\ssum$, scalar product and function application on scalars ($f_{1\times 1}$), we can simulate full function application, as follows:
 $$
f(e_1,\ldots, e_k) :=\Sigma v_i \Sigma v_j. f_{1\times 1}(v_i^T\cdot e_1\cdot v_j, \ldots ,v_i^T\cdot e_k\cdot v_j) \times v_i\cdot v_j^T.
$$

\item  This is useful when the function allowed is $\kprod$, since one can be computed using the other and viceversa.
Note that, if $\ssum$ is present, multiplication function application on matrices of any size can be simulated as 
$$
f_{\kprod}(e_1,\ldots, e_n) :=\Sigma x_i \Sigma x_j. (x_i^T\cdot e_1\cdot x_j)\times \ldots \times (x_i^T\cdot e_n\cdot x_j) \times x_i\cdot x_j^T,
$$
which also holds if $e_1,\ldots, e_n$ are scalars. Furthermore, if we restrict $f_{\kprod}$ to
work only on scalars, it is enough to simulate scalar product (and thus, full function application). Let $c$ a scalar:
$$
c\times A :=\Sigma x_i \Sigma x_j. f_{\kprod}(c, x_i^T\cdot A\cdot x_j) \times x_i\cdot x_j^T,
$$




\item The constant in expressions are assumed to be $1\times 1$ matrices. 
For instance, when we write $(1-e_{\ones}(v)^T\cdot v)$ we actually mean $([1]-e_{\ones}(v)^T\cdot v)$.


\end{itemize}