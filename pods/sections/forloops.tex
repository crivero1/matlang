%Probably the longest section.


%\begin{itemize}
%\item Define the syntax and the semantics of for loop language. 
%\item Examples:
%\begin{itemize}
%\item Simple queries (cover \lang\)
%\item Elementary operations
%\item How to define order (the $Z$ matrix, $v_{max}$,...)
%\item Standard Linear Algebra algorithms:
%\begin{itemize}
%\item Gaussian elimination
%\item Inverse
%\item Determinant
%\item $LU$
%\item $\cdots$
%\end{itemize}
%\end{itemize}
%\end{itemize}

% While \lang\ serves as a solid basis for expressing linear algebra properties, it is still somewhat lacking when defining more advanced linear algebra operators such as Gaussian eliminations, or computing an inverse of a matrix. To alleviate these issues, we propose an extended version of \lang, called \langfor which allows us to express such properties.
%
%As before, we assume a countably infinite set of matrix variables $\Mvar = \{V_1, V_2, \ldots\}$, and a set $\Fun$  of functions $f:\mathbb{C}^n \mapsto \mathbb{C}$. Additionally, for each $n\in \mathbb{N}$, we denote by $e_1^n,\ldots ,e_n^n$ the complete list of canonical vectors of dimension $n$; that is, $e_1^n = [1\ 0 \cdots 0]^*$, $e_2^n = [0\ 1\ 0 \cdots 0]^*$, etc. When $n$ is clear from the context we will simply write $e_1,e_2$, etc. The syntax of \langfor is defined as follows:


%\medskip

%\begin{tabular}{lcll}
%$e$ & $::=$ & $V\in \Mvar$ & (matrix variable)\\
 %& $|$ & $e^*$ & (conjugate transpose)\\ 
 %& $|$ & $e_1 \cdot e_2$ & (matrix multiplication)\\   
 %& $|$ & $e_1 + e_2$ & (matrix addition)\\    
 %& $|$ & $f(e_1,\ldots ,e_n)$ & (application of $f\in \Fun$)\\
 %& $|$ & $\ffor{v}{X}{e}$ & (canonical for loop, with $v, X \in \Mvar$). 
%\end{tabular}


To extend \lang\ we take inspiration from classical linear algebra algorithms, such as those described in \cite{num}. Many of these algorithms are based on \textit{for loops} and in which the termination conditions for the loops are determined by matrix dimensions. We have seen how shortest path can be computed using for loops in the Introduction. As another example, consider the following program which takes
an $n\times n$ matrix $A$ as input:
\begin{tabbing}
$4\mathsf{clique}:=0$\\
\texttt{for}\=\,  $i,j,k,\ell\in[1..n]$. \\
\> \texttt{if} \= $i\neq j$ \& $i\neq k$ \& $i\neq \ell$ \& $j\neq k$ \& $j\neq \ell$ \& $k\neq\ell$ \texttt{do}:\\
\> \> $4\mathsf{clique}:= 4\mathsf{clique} + A_{ij}\cdot A_{ik}\cdot A_{i\ell} \cdot A_{jk}\cdot A_{j\ell} \cdot A_{k\ell}$.  
\end{tabbing}
Clearly, when $A$ is the adjacency matrix of a graph $G$, $4\mathsf{clique}\neq 0$ if and only if $G$ contains a four-clique. Another program, again with an $n\times n$ matrix $A$ as input, is the following:
\begin{tabbing}
B:=I\quad /* $I$ is the $n\times n$ identity matrix */\\\	
\texttt{for}\=\,  $i\in[1..n]$.\\
\> $B:=B\cdot (I+A)$\quad \\
\textsf{TC}:=$f_{>0}(B)$,
\end{tabbing}
where $f_{>0}:\RR\to\RR$ is such that $f_{>0}(x):=1$ if $x>0$ and $f_{>0}(x):=0$ otherwise. It is readily verified that when $A$ is the adjacency matrix of a graph $G$, then \textsf{TC} is the adjacency matrix of the transitive closure of $G$. These two examples already show that for loops allow computing properties beyond what \lang\ can express.
We see more advanced examples, such as Gaussian elimination and computing an inverse of a matrix, later in the paper. With this motivation in mind, we next extend \lang\ with for loops. We refer to this extension as \langfor. 

%
%
%  which commonly use loops whose termination conditions are determined by the matrix dimension, and will allow us to express many properties of interest.
%
% As before, we assume a countably infinite set of matrix variables $\Mvar = \{V_1, V_2, \ldots\}$, and a set $\Fun$  of functions $f:\mathbb{C}^n \mapsto \mathbb{C}$. Additionally, for each $n\in \mathbb{N}$, we denote by $e_1^n,\ldots ,e_n^n$ the complete list of canonical vectors of dimension $n$; that is, $e_1^n = [1\ 0 \cdots 

\subsection{Syntax and semantics} The syntax of \langfor is defined just as for \lang\, but with an extra rule in the grammar:
\medskip

\begin{tabular}{lcll}
 $\ffor{v}{X}{e}$ & (canonical for loop, with $v, X \in \Mvar$). 
\end{tabular}

\medskip
Intuitively, $X$ is a matrix variable which is iteratively updated according to the expression $e$. We simulate iterations of the form ``\texttt{for} $i\in [1..n]$'' by letting $v$ loop over the \textit{canonical vectors} of dimension $n$. That is,
for each $n\in \mathbb{N}$, we denote by $b_1^n,\ldots ,b_n^n$ the complete list of canonical vectors of dimension $n$; that is, $b_1^n = [1\ 0 \cdots 0]^T$, $b_2^n = [0\ 1\ 0 \cdots 0]^T$, etc. When $n$ is clear from the context we simply write $b_1,b_2,\ldots$. In addition, $e$ may depend on $v$. We next make the semantics precise and start by
declaring the type of loop expressions.
Given a schema $\Sch$, the type of a \langfor expression $e$, denoted $\ttype(e)$, is defined inductively as in \lang\, but with following extra rule:
\begin{itemize}
\item $\ttype(\ffor{v}{X}{e}) = \ttype(e)$, if $\ttype(X) = \ttype(e)$, and $\ttype(v) = (\gamma,1)$; and is undefined otherwise.
\end{itemize}

%Similarly as when defining \lang\, here we start with a core set of matrix operations (i.e sum, product, and the transpose of a matrix). In addition to this, we allow applying functions, and  the $\ffor{v}{X}{e}$ construct, which allows looping over the canonical vectors of a specified dimension, and updating the context of the variable $X$ in each iteration. The latter operator is inspired by classical Linear Algebra algorithms \cite{num}, which commonly use loops whose termination conditions are determined by the matrix dimension, and will allow us to express many properties of interest.

%A \langfor {\em schema} $\Sch$ is a pair $\Sch=(\Mnam,\size)$, where $\Mnam\subset \Mvar$ is a finite set of matrix variables, and $\size: \Mvar \mapsto \DD\times \DD$ is a function that maps each matrix variable to a pair of {\em size symbols}. Given a schema $\Sch$, the type of a \langfor expression, denoted $\ttype(e)$, is defined inductively as follows:
%\begin{itemize}
%\item $\ttype(V) = \size(V)$, for a matrix variable $V$,
%\item $\ttype(e^*) = (\beta,\alpha)$, if $\ttype(e)=(\alpha,\beta)$; and undefined if $\ttype(e)$ is undefined,
%\item $\ttype(e_1 \cdot e_2) = (\alpha,\gamma)$, whenever $\ttype(e_1)=(\alpha,\beta)$, and $\ttype(e_2)=(\beta,\gamma)$; and is undefined otherwise,
%\item $\ttype(e_1 + e_2) = \ttype(e_1)$, if $\ttype(e_1) = \ttype(e_2)$; and is undefined otherwise,
%\item $\ttype(f(e_1,\ldots ,e_n)) = (1,1)$, whenever $\ttype(e_1)= \cdots =\ttype(e_n)=(1,1)$, and $f:\mathbb{C}^n\mapsto \mathbb{C}$; and is undefined otherwise,
%\item $\ttype(f(e_1,\ldots ,e_n)) = (\alpha,\beta)$, whenever $\ttype(e_1) = \ldots = \ttype(e_k) = (\alpha,\beta)$, and $f:\mathbb{C}^n \mapsto  \mathbb{C}$; and is undefined otherwise, and,
%\item $\ttype(\ffor{v}{X}{e}) = \ttype(e)$, if $\ttype(X) = \ttype(e)$, and $\ttype(v) = (\gamma,1)$; and is undefined otherwise.
%\end{itemize}
%\cristian{Is this the same than in the previous section? Is there any difference?}

% To extend \lang\, we add $\ffor{v}{X}{e}$ construct, which allows looping over the canonical vectors of a specified dimension, and updating the context of the variable $X$ in each iteration. The latter operator is i
%
% A \langfor {\em schema} $\Sch$ is a pair $\Sch=(\Mnam,\size)$, where $\Mnam\subset \Mvar$ is a finite set of matrix variables, and $\size: \Mvar \mapsto \DD\times \DD$ is a function that maps each matrix variable to a pair of {\em size symbols}. 
We remark that in the expression $\ffor{v}{X}{e}$, we require that $\ttype(X) = \ttype(e)$ as this expression updates the content of the variable $X$ in each iteration using the result of $e$. We further restrict the type of 
$v$ to be of a vector type, i.e., $\ttype(v)=(\gamma,1)$, since $v$ will be instantiated with canonical vectors.
% As we will see below, evaluating $e$ will depend on a canonical vector stored in $v$, and the current content of $X$. %Another difference from \lang\ is that we allow function application only on scalars (more precisely, on $1\times 1$ matrices).
%
A \langfor\ expression $e$ is well-typed over a schema $\Sch$ if its type is defined. For well-typed expressions we can define the evaluation, just as for \lang. To define the semantics of $\ffor{v}{X}{e}$ over an instance $\I$, we need the following notation. Let $\I$ be an instance and $V\in \Mnam$. Then $\I[V := A]$ denotes an instance that coincides with $\I$, apart from the fact that the value of the matrix variable $V$ is the matrix $A$. Assume that
$\ttype(v)= (\gamma,1)$, and $\ttype(e) = (\alpha,\beta)$ and $n := \dom(\gamma)$. Then, $\sem{\ffor{v}{X}{e}}{\I}$ is defined iteratively, as follows:
\begin{itemize}
\item Let $A_0 = \mathbf{0}$, be the zero matrix of size $\dom(\alpha)\times \dom(\beta)$.
\item For $i=1,\ldots n$, compute $A_i = \sem{e}{\I[v := b^{n}_i, X:= A_{i-1}]}$.
\item Finally, set $\sem{\ffor{v}{X}{e}}{\I} = A_{n}$.
\end{itemize}

%%
% A \langfor {\em instance} $\I$ over a schema $\Sch$, is a pair $\I = (\dom,\conc)$, where $\dom : \DD \mapsto \mathbb{N}$ assigns a value to each size symbol, and $\conc : \Mnam \mapsto \mtr{\mathbb{C}}$ assigns a concrete matrix to each matrix variable $M\in \Mnam$, such that $\dim(\conc(M)) = \dom(\alpha)\times \dom(\beta)$, where $\size(M) = (\alpha,\beta)$. As before, we assume that $\dom(1) = 1$, for every instance $\I$.
%  %(meaning that $e_1^n = \begin{bmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{bmatrix}$, etc.).
% If $\I$ is an instance, $V$ a matrix variable such that $\size(V)= (\alpha,\beta)$, and $M$ a matrix of dimension $\dom(\alpha)\times \dom(\beta)$, then $\I[V := M]$ denotes an instance that coincides with $\I$, apart from the fact that the value of the matrix variable $V$ is the matrix $M$.
% %If $e$ is a well-typed expression according to $\Sch$, then we denote by $\sem{e}{\I}$ the matrix obtained by evaluating $e$ over $\I$, and define it as follows:
% %\begin{itemize}
% %\item $\sem{M}{\I} = \conc(M)$, for $M\in \Mnam$;
% %\item $\sem{e^*}{\I} = \sem{e}{\I}^*$, where $M^*$ is the conjugate transpose of a matrix $M$;
% %\item $\sem{e_1\cdot e_2}{\I} = \sem{e_1}{\I} \cdot \sem{e_2}{\I}$;
% %\item $\sem{e_1 + e_2}{\I} = \sem{e_1}{\I} + \sem{e_2}{\I}$;
% %\item $\sem{f(e_1,\ldots ,e_n)}{\I}$ is a $1\times 1$ matrix whose only entry has the value $f(\sem{e_1}{\I},\ldots ,\sem{e_n}{\I})$. Here we abuse the notation and use $\sem{e}{\I}$ to denote both a $1\times 1$ matrix, and a scalar from $\mathbb{C}$.
% %\item $\sem{f(e_1,\ldots ,e_n)}{\I}$ is a matrix $A$ of the same size as $\sem{e_1}{\I}$, and where $A_{ij}$ has the value $f(\sem{e_1}{\I}_{ij},\ldots ,\sem{e_n}{\I}_{ij})$.
% %\end{itemize}
% %\cristian{The same as with the type function, we can reuse the semantics of the previous section.}
%
% If $e$ is a well-typed expression according to $\Sch$, then we denote by $\sem{e}{\I}$ the matrix obtained by evaluating $e$ over $\I$, and define it as in \lang\, adding the new operator.
% \floris{Perhaps it is insightful to already give an easy example here, e.g., clique. Perhaps even better are the very simple expressions for diag and one vector. The text below is quite
% cryptic.}
%
% Notice that evaluating $\ffor{v}{X}{e}$ over an instance that already assigns values to $v$ and $X$, these values get overwritten immediately. Notice that if $e$ does not use the variable $v$, then it will have the same value in each iteration. Sometimes when we want to make it explicit that the expression $e$ uses matrix variables $X_1,\ldots ,X_n$, we write $e(X_1,\ldots ,X_n)$, where $X_1,\ldots ,X_n$ are all the matrix variables mentioned in $e$. Analogously with First Order Logic, we could define the notion of free and bound variables (i.e. the ones in the scope of a \texttt{for} operator), however, since we explicitly rewrite the value of these variables, this distinction will not play an important role.
%
%
% \cristian{I don't understand this comment of free and bound variables. What do you mean? I believe than similar than in first order variables, one can define this concept, but here it is not used.}
%
% %\subsection{Examples of \langfor expressions}




%%needs dimensions:
%Next we illustrate the versatility of the introduced language. To begin, we note that, unlike the original \lang\ proposal, we have at our disposals canonical vectors of arbitrary dimension. The most basic use of canonical vectors is for accessing a position $ij$ of some matrix $M$, a property which lies outside of the scope of \lang. For this, we can simply use the expression $(e_i^{n})^*\cdot M \cdot e_j^m$, where $M$ is a matrix of size $m\times n$, $e_i^n$ is the $i$th canonical vector of dimension $n$, and likewise, $e_j^m$ is the $j$th canonical vector of dimension $m$.

For a better understanding how \langfor  works, we provide some simple examples.
% next present a series of properties that the language can express and introduce some operators that will be commonly used throughout the paper.
% , and show how the proposed language captures original \lang.
\subsection{Examples}
We first show how one can construct the identity matrix of a certain dimension. For this, it suffices to use the expression $$e_{\mathsf{Id}}:=\ffor{v}{X}{X + v\cdot v^T}.$$ For this expression to be well-typed, $v$ has to be a vector variable of type $\alpha\times 1$ and $X$ a matrix variable of type $(\alpha,\alpha)$. When evaluated over some instance $\I$, this loop starts by initializing $X$ as the zero matrix of dimension $n\times n$, where $n=\dom(\alpha)$, and then adds to $X$ the matrix $b_1^n\cdot (b_1^n)^T$ in the first iteration, the matrix $b_2^n\cdot (b_2^n)^T$ in the second iteration, and so on, until finally $b_n^n\cdot (b_n^n)^T$ is added. Hence, $X$ equals the identity matrix of dimension $n\times n$ in the end.
As another example, recall the $\diag$ operator from \lang.	This operator is redundant in \langfor. Indeed, a minor variation of the expression $e_{\mathsf{Id}}$ suffices:
$$e_{\mathsf{diag}}:=\texttt{for } v, X. X + (v^T\cdot e) \times v\cdot v^T,$$ where $e$ is a \langfor\  expression of type $(\alpha,1)$. The difference with $e_{\mathsf{Id}}$ is that instead of the value $1$, the value 
$b_i^T\cdot\sem{e}{\I}=\sem{e}{\I}_{i}$ is put on position $i$ on the diagonal, when evaluating $e_{\mathsf{diag}}$ on $\I$.
%  One can verify that for the above expression to be well-typed, $v$ needs to be of type $(\alpha,1)$ and $X$ of type $(\alpha,\alpha)$. When evaluated over some instance $\I$, $X$ is initialised with the zero matrix of dimension $n\times n$, where $n=\dom(\alpha)$. Then, in iteration $i$, the $n\times n$-matrix
% $b_i^T\cdot \sem{e}{\I}\times (b_i\cdot b_i^T)$ is added. In other words, on the $i$th element of the diagonal, represented by $b_i\cdot b_i^T$, the value $b_i^T\cdot\sem{e}{\I}=\sem{e}{\I}_{i}$ is added. 
That is, the expression $e_{\mathsf{diag}}$ evaluates to $\sem{\diag(e)}{\I}$. It is also readily verified that the one-vector operator in \lang\ becomes redundant in \langfor. Furthermore, general function applications can be simulated in \langfor\ by just assuming function applications $f(e_1,\ldots,e_k)$ for $f\in\Fun_k$ where $\ttype(e_i)=(1,1)$ for all $i\in[k]$. Indeed,  consider the \langfor\ expression 
\begin{multline*}
e=\texttt{for }v,X.\, X + \\ 
\texttt{for }w,Y.\, Y + v\cdot f(v^T\cdot e_1\cdot w, \ldots, v^T\cdot e_k\cdot w)\cdot w^T. 
\end{multline*}
In the expression above, we basically loop over all positions in $\sem{e_i}{\I}$, one by one, and apply the function $f$ on those positions.  One can see that $\sem{e}{\I}=\sem{f(e_1,\ldots,e_k)}{\I}$ for $e_i$'s of arbitrary type, but that $f$ is only
applied on expressions of type $(1,1)$, such as $v^T\cdot e_i\cdot w$. 
%
%
% \smallskip
% \noindent
% \textbf{Core operators}. The previous example show that we can define \langfor\ using a small number of core operators, whilst still extending \lang. In particular, it suffices to define \langfor to consist of expressions of the form
% %
% %
% %
% % Note that the  \texttt{for} operator is much more powerful that it seems. We can simulate some operations of the original \lang\ semantics. Assume the allowed expressions are
%
% \begin{tabular}{lcll}
% $e$ & $:=$ & $V\in \Mvar$ & (matrix variable)\\
%  % & $|$ & $e^T$ & (transpose)\\
%  & $|$ & $e_1 \cdot e_2$ & (matrix multiplication)\\
%  % & $|$ & $e_1 + e_2$ & (matrix addition)\\
%  & $|$ & $\text{apply}[f](e_1,\ldots ,e_k)$ & (application of $f\in \Fun$)\\
%  & $|$ & $\ffor{v}{X}{e}$ & (canonical for loop, with $v, X \in \Mvar$).
% \end{tabular}
%
% Where function application $\text{apply}[f]$ works only on scalars. This is
%
% \begin{itemize}
% \item $\ttype(\text{apply}[f](e_1,\ldots ,e_n)) = (1,1)$, whenever $\ttype(e_1)= \cdots =\ttype(e_n)=(1,1)$, and $f:\mathbb{C}^n\mapsto \mathbb{C}$; and is undefined otherwise.
% \item $\sem{\text{apply}[f](e_1,\ldots ,e_n)}{\I}$ is a $1\times 1$ matrix whose only entry has the value $f(\sem{e_1}{\I},\ldots ,\sem{e_n}{\I})$.
% \end{itemize}

These examples illustrate that we can limit \langfor to consist of the following ``core'' operators: transposition, matrix multiplication and pointwise function application $f(e_1,\ldots,e_k)$ for $f\in\Fun_k$ where each $e_i$
has type $(1,1)$. 

We also observe that the $4\textsf{clique}$ program mentioned at the beginning of this section can 
be expressed in \langfor. Indeed, it suffices to consider the expression
\begin{tabbing}
\texttt{for }\=$u,X_1.\, X_1 + $\\
\> \texttt{for }\=$v,X_2.\, X_2 +$ \\
\>\>\texttt{for }\=$w,X_3.\, X_3 +$ \\
\>\>\>\texttt{for }\=$x,X_4.\, X_4 +$ \\
\>\>\>\>$u^T\cdot M\cdot v \cdot u^T\cdot M\cdot w\cdot u^T\cdot M\cdot x \cdot $\\
\>\>\>\>$v^T\cdot M\cdot w \cdot v^T\cdot M\cdot x\cdot w^T\cdot M\cdot x \cdot g(u,v,w,x)$\\
\end{tabbing}
with $g(u,v,w,x)=f(u,v)\cdot f(u,w)\cdot f(u,x)\cdot f(v,w)\cdot f(v,x)\cdot f(w,x)$ and
$f(u,v)=1-u^T\cdot v$. Note that $f(b_i^n,b_j^n)=1$ if $i\neq j$ and $f(b_i^n,b_j^n)=0$ otherwise.
Hence, $g(b_i^n,b_j^n,b_k^n,b_\ell^n)=1$ if and only if all $i,j,k,l$ are pairwise different.
When evaluating the expression on an instance $\I$ such that $M$ is assigned to the adjacency 
matrix of a graph, the expression above evaluates to a non-zero value if and only if the graph
contains a four-clique.
%
% % =\begin{cases}
% %                0 \text{ if } u=v \\
% %                1 \text{ if } u\neq v
% %             \end{cases}
% % 		\]
%
% To distinguish four-cliques, we will need to determine whether we are dealing with four different nodes. For this, we will utilize the function $$g(u,v,w,r)=f(u,v)\cdot f(u,w)\cdot f(u,r)\cdot f(v,w)\cdot f(v,r)\cdot f(w,r),$$

\subsection{Loop Initialization} As the reader may have observed, in the semantics of \texttt{for} loops we 
always initialise $A_0$ to the zero matrix $\mathbf{0}$ (of appropriate dimensions). It is often convenient
to start the iteration given some concrete matrix  originating from the result of evaluation a \langfor\ expression $e_0$. To make this explicit, we write $\initf{e_0}{v}{X}{e}$ and its semantics is defined as above
with the difference that $A_0:=\sem{e_0}{\I}$. We observe, however, that $\initf{e_0}{v}{X}{e}$ can already
be expressed in \langfor. In other words, we do not loose generality by assuming an initialisation of $A_0$ by $\mathbf{0}$.
The key insight is that in \langfor\ we can check during evaluation whether or not
the current canonical vector $b_i^n$ is equal to the $b_1^n$. This is not entirely trivial to see and is due to fact that \texttt{for} loops iterate over the canonical vectors in a fixed order. We will explore the impact of this order in the next section. In particular, we can define a \langfor expression $\mmin$, which when evaluated on an instance, will return $1$ if its input vector is $b_1^n$, and return $0$ otherwise. Given $\mmin$, consider now the
\langfor\ expression
 $$\ffor{v}{X}{\mmin{v}\cdot e(v,X/e_0) + (1-\mmin{v})\cdot e(v,X)},$$
 where we explicitly list $v$ and $X$ as matrix variables on which $e$ potentially depends on, and where
 $e(v,X/e_0)$ denotes the expression obtained by replacing every occurrence of $X$ in $e$ with $e_0$.
%
%  As mentioned previously, all of the iterations in \texttt{for} loops start by initializing $A_0$ to the null matrix. We have already seen that this property is useful for defining the extremal points of our ordering, however, sometimes we would like to start the iteration using some concrete matrix $B$. Using the operator $\mmin$, we can actually achieve this as follows. First, let $\ffor{v}{X}{e(v,X)}$ be the \texttt{for} loop that begins iterating from the null matrix. Here we write $e(v,X)$ to denote the variables that $e$ potentially (but not necessarily) uses. To start the iteration from $B$ it now suffices to use the following loop:
% $$\ffor{v}{X}{\mmin{v}\cdot e(v,X/B) + (1-\mmin{v})\cdot e(v,X)} \quad (\dag),$$
% where $e(v,X/B)$ denotes the expression obtained by replacing every occurrence of $X$ in $e$ with $B$.
When evaluating this expression on an instance $\I$, $A_0$ is initial set to the zero matrix, in the first iteration (when  $v=b_1^n$ and thus $\mmin{v}=1$)
we have $A_1=\sem{e}{\I[v:=b_1^n,X:=\sem{e_0}{\I}]}$, and for consecutive iterations (when only the part related to $1-\mmin{v}$ applies) $A_i$ is updated as before. Clearly, the result of this evaluation is equal to
$\sem{\initf{e_0}{v}{X}{e}}{\I}$. 

As illustration, we consider the transitive closure program from the beginning of this section. We can
express this in \langfor. Indeed, consider the expression 
$$
f_{>0}\left(\initf{e_{\mathsf{Id}}}{v}{X}{X\cdot (e_{\mathsf{Id}}+M)}\right),
$$
where $e_{\mathsf{Id}}$ is the \langfor\ expression constructing the identity matrix $I$, as explained earlier.
Observe that we start the loop using an initialisation by $I$. Hence, when evaluated on an instance $\I$ such that $M$ is an adjacency matrix $A$ of a graph, the expression above simply computes $(I+A)^n$, followed by the pointwise function application $f_{>0}$. In other words, it returns the adjacency matrix of the transitive closure of $G$.
% \smallskip
% \noindent
% \textbf{More examples}. We conclude by showing that the two examples at the beginning of this section can be
% expressed in \langfor. Indeed, for $4\mathsf{clique}$ it suffices to consider
%
% The modified \texttt{for} expression will now use $B$ as the assignment of $X$ in the very first iteration (as determined by $\mmin{v}$), and will proceed as before whenever $v$ is not equal to the first canonical vector, thus defining the desired result. Since starting iteration with a non null matrix is often useful, we will denote  by $\initf{B}{v}{X}{e}$ the expression $(\dag)$.

% \noindent{\bf For loops.}
% The biggest novelty of $\langfor$ is the for operator. To illustrate how this operator can be used, we first show how one can construct the identity matrix of needed dimension in \langfor.

%%NOT DOABLE IF NO ACCESS TO DIMENSION
%\noindent{\bf Elementary matrix operations.} Here we show the true value of adding canonical vectors to the language, by illustrating how they allow us to express elementary matrix operations \cite{linalg}:
%\begin{enumerate}
%\item {\bf Row switching.} To switch the row $i$ and row $j$ of an $m\times n$ matrix $M$, we can simply use the expression $T^{ij} \cdot M$, where:
%$$T^{ij} = I^m - e_i^m\cdot (e_i^m)^* - e_j^m\cdot (e_j^m)^* + e_i^m\cdot (e_j^m)^* + e_j^m\cdot (e_i^m)^*.$$
%\item {\bf Row multiplication.} Multiplying a row by a scalar $c$ is performed by 
%\item {\bf Row addition.}
%\end{enumerate}
%Analogously, we can perform these transformations of columns, by using the transposed matrix $M^*$, and the canonical vectors of appropriate dimension.

% To begin with, consider the expression $$v_{max} := \ffor{v}{X}{v}.$$
% we can easily obtain the last canonical vector using the expression
% \medskip
%
% \noindent{\bf Core operators}
% Note that the  \texttt{for} operator is much more powerful that it seems. We can simulate some operations of the original \lang\ semantics. Assume the allowed expressions are
%
% \begin{tabular}{lcll}
% $e$ & $:=$ & $V\in \Mvar$ & (matrix variable)\\
%  & $|$ & $e^T$ & (transpose)\\
%  & $|$ & $e_1 \cdot e_2$ & (matrix multiplication)\\
%  & $|$ & $e_1 + e_2$ & (matrix addition)\\
%  & $|$ & $\text{apply}[f](e_1,\ldots ,e_n)$ & (application of $f\in \Fun$)\\
%  & $|$ & $\ffor{v}{X}{e}$ & (canonical for loop, with $v, X \in \Mvar$).
% \end{tabular}
%
% Where function application $\text{apply}[f]$ works only on scalars. This is
%
% \begin{itemize}
% \item $\ttype(\text{apply}[f](e_1,\ldots ,e_n)) = (1,1)$, whenever $\ttype(e_1)= \cdots =\ttype(e_n)=(1,1)$, and $f:\mathbb{C}^n\mapsto \mathbb{C}$; and is undefined otherwise.
% \item $\sem{\text{apply}[f](e_1,\ldots ,e_n)}{\I}$ is a $1\times 1$ matrix whose only entry has the value $f(\sem{e_1}{\I},\ldots ,\sem{e_n}{\I})$.
% \end{itemize}
%
% \subsection{Minimal Core}
% We have the following:
%
% \begin{itemize}
% \item {\em Pointwise function application.} Note that
%
% \begin{align*}
% f(e_1,\ldots, e_n)&=\\
% &\texttt{for }v,X.\quad X + \\
% &\quad \texttt{for }w,Y.\quad Y + \\
% &\quad \quad v\left[ \text{apply}[f](v^Te_1w, \ldots, v^Te_nw) \right] w^T
% \end{align*}
%
% \item {\em Conjugate transpose.} Let $\texttt{conj}(a) := \overline{a}$ be the conjugate function. Then we can simulate the conjugate transpose of expression $e$ as $\texttt{conj}(e^T)$.
% \item {\em One vector.} Using the function $f(x) := 1$, we can define $$\ones(e) := f(\texttt{for } v,X. X + e\cdot v).$$
% \item {\em Multiplying a matrix by a scalar.} Let $c$ be a scalar ($1\times 1$ matrix) and $f_{\times}(a, b) := a \times b$ . Then, for an expression $e$, $c\odot e := f_{\times}(\ones(e)\cdot c \cdot \ones(e^T)^T, e)$.
% \item {\em Diagonal of a vector.} The operator $\diag(e)$ can be defined as:
% $$\diag(e) := \texttt{for } v, X. X + (v^T\cdot e) \odot vv^T.$$
% \end{itemize}
%
% \section{Order!!}
%
% \noindent{\bf Order.} The \texttt{for} operator assumes that canonical vectors come in some particular order, however, it does not give us an immediate access to this order. An interesting question is whether, using the \texttt{for} loops, we can define a \langfor expression which allow us to define the order of canonical vectors. Next we show that this is indeed possible. To begin with, we can easily obtain the last canonical vector using the expression $$v_{max} := \ffor{v}{X}{v}$$
%
% The fundamental property of iteration we use here is that the result variable is always initiated with the null matrix. Therefore the loop above will simply keep on storing the current canonical vector before returning the final one. The ability to do this sort of manipulation was one of the reasons why we initiate $A_0$ in the semantics of \texttt{for} to null matrix.
%
% To define an order relation for canonical vectors, notice that the following matrix:
% \[
% Z_{eq} = \begin{bmatrix}
%     1 & 1 & \cdots &  1 \\
%     0 & \ddots & \ddots & \vdots \\
%     \hdotsfor{3} & 1 \\
%     0 & \cdots & \cdots & 1
% \end{bmatrix},
% \]
% has the property that $e_i^*\cdot Z_{eq} \cdot e_j$, for two canonical vectors $e_i,e_j$ of the same dimension, is equal to one if and only $i\leq j$, and is zero otherwise. $Z_{eq}$ can easily de defined in \langfor as follows:
% $$Z_{\text{eq}}=\ffor{v}{X}{X + \left[ (Xv_{max}) + v \right]v^* + vv^*_{max}},$$
% where $v_{max}$ is as defined above. The intuition behind this expression is that using the last canonical vector $v_{max}$, we have access to the final column of $X$ (via the product $X\cdot v_{max}$), to which we add the current canonical vector $v$, thus constructing $Z_{eq}$ by filling it column by column. By defining $$\lleq{u}{v} := u^*\cdot Z_{eq} \cdot v,$$
% we obtain an order relation that allows us to discern whether one canonical vector comes before the other in the order given by \texttt{for}. If we want a strict order, we can just use $Z_< := Z_{eq} - I$.
%
% Interestingly, we can also define the predecessor relation between canonical vectors. For this, we require the following matrix:
% %\[
% %S := \begin{bmatrix}
% %    0 & 1         & 0         & \cdots &  0 \\
% %    0 & \ddots & 1         & \cdots & 0 \\
% %    \vdots & \vdots & \ddots & \ddots & \vdots \\
% %    \hdotsfor{3} & \ddots & 1 \\
% %    0 & \cdots & \cdots & \cdots & 0
% %\end{bmatrix}.
% %\]
% \[
% S = \begin{bmatrix}
%     0 & 1 & \cdots &  0 \\
%     0 & \ddots & \ddots & \vdots \\
%     \hdotsfor{3} & 1 \\
%     0 & \cdots & \cdots & 0
% \end{bmatrix},
% \]
% Using this matrix, we have that for a canonical vector $e_i$:
% \[
%   			S\cdot e_i=\begin{cases}
%                e_{i-1}, \text{ if } i > 1 \\
%               \mathbf{0}, \text{ if } i = 1
%             \end{cases}
% 		\]
% where $\mathbf{0}$ is a vector of zeros of the same type as $e_i$. Notice also that $\ones(v)^*\cdot S \cdot v$ is equal to zero, for a canonical vector $v$, if and only if $v = e_1$ is the first canonical vector, and zero otherwise. To define the first canonical vector in the order given by \texttt{for}, we can then write:
% $$v_{min} := \ffor{v}{X}{\mmin{v}\cdot v},$$
% where the expression $\mmin{v}$ is defined as $\mmin{v} := 1 - \ones(v)^*\cdot S \cdot v$, and, when evaluated over canonical vectors, will result in $1$ if and only if $v=e_1$ is the first canonical vector. Finally, we denote that $S$ can be defined using the following \langfor expression:
% \begin{multline*}
% S:= \texttt{for }v,X.\quad X + \\
% \left[ (1 - v^*v_{max})vv_{max}^* - (Xv_{max}) v_{max}^* + (Xv_{max})v^*\right].
% \end{multline*}
%
%
%
%
