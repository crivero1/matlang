%!TEX root = ../main.tex
% !TeX spellcheck = en_US



To extend \lang\ with recursion, we take inspiration from classical linear algebra algorithms, such as those described in \cite{num}. Many of these algorithms are based on \textit{for-loops} in which the termination condition for each loop is determined by the matrix dimensions. We have seen how the transitive closure of a matrix can be computed using for-loops in the Introduction. Here we add this ability to \lang, and show that the resulting language, called $\langfor,$ can compute properties outside of the scope of \lang. We see more advanced examples, such as Gaussian elimination and matrix inversion, later in the paper. 
%computing the inverse of a matrix, 

\subsection{Syntax and semantics of \langfor} The syntax of \langfor is defined just as for \lang but with an extra rule in the grammar:
\medskip

\begin{tabular}{lcll}
 $\ffor{v}{X}{e}$ & (canonical for loop, with $v, X \in \Mvar$). 
\end{tabular}

\medskip
\noindent Intuitively, $X$ is a matrix variable which is iteratively updated according to the expression $e$. We simulate iterations of the form ``\texttt{for} $i\in [1..n]$'' by letting $v$ loop over the \textit{canonical vectors} $b_1^n,\ldots,b_n^n$ of dimension $n$. Here,
%
% That is,
% for each $n\in \mathbb{N}$, we denote by $b_1^n,\ldots ,b_n^n$ the  canonical vectors of dimension $n$; that is,
$b_1^n = [1\ 0 \cdots 0]^T$, $b_2^n = [0\ 1\ 0 \cdots 0]^T$, etc. When $n$ is clear from the context we simply write $b_1,b_2,\ldots$. In addition, the expression $e$ in the rule above may depend on $v$. 

We next make the semantics precise and start by
declaring the type of loop expressions.
Given a schema $\Sch$, the type of a \langfor expression $e$, denoted $\ttype(e)$, is defined inductively as in \lang but with following extra rule:
\begin{itemize}
\item $\ttype(\ffor{v}{X}{e}) := (\alpha,\beta)$, if \\
$\ttype(e)=\ttype(X) =(\alpha,\beta)$ and $\ttype(v) = (\gamma,1)$.
\end{itemize}
We note that $\Sch$ now necessarily includes $v$ and $X$ as variables and assigns size symbols to them.
%Similarly as when defining \lang\, here we start with a core set of matrix operations (i.e sum, product, and the transpose of a matrix). In addition to this, we allow applying functions, and  the $\ffor{v}{X}{e}$ construct, which allows looping over the canonical vectors of a specified dimension, and updating the context of the variable $X$ in each iteration. The latter operator is inspired by classical Linear Algebra algorithms \cite{num}, which commonly use loops whose termination conditions are determined by the matrix dimension, and will allow us to express many properties of interest.
%A \langfor {\em schema} $\Sch$ is a pair $\Sch=(\Mnam,\size)$, where $\Mnam\subset \Mvar$ is a finite set of matrix variables, and $\size: \Mvar \mapsto \DD\times \DD$ is a function that maps each matrix variable to a pair of {\em size symbols}. Given a schema $\Sch$, the type of a \langfor expression, denoted $\ttype(e)$, is defined inductively as follows:
%\begin{itemize}
%\item $\ttype(V) = \size(V)$, for a matrix variable $V$,
%\item $\ttype(e^*) = (\beta,\alpha)$, if $\ttype(e)=(\alpha,\beta)$; and undefined if $\ttype(e)$ is undefined,
%\item $\ttype(e_1 \cdot e_2) = (\alpha,\gamma)$, whenever $\ttype(e_1)=(\alpha,\beta)$, and $\ttype(e_2)=(\beta,\gamma)$; and is undefined otherwise,
%\item $\ttype(e_1 + e_2) = \ttype(e_1)$, if $\ttype(e_1) = \ttype(e_2)$; and is undefined otherwise,
%\item $\ttype(f(e_1,\ldots ,e_n)) = (1,1)$, whenever $\ttype(e_1)= \cdots =\ttype(e_n)=(1,1)$, and $f:\mathbb{C}^n\mapsto \mathbb{C}$; and is undefined otherwise,
%\item $\ttype(f(e_1,\ldots ,e_n)) = (\alpha,\beta)$, whenever $\ttype(e_1) = \ldots = \ttype(e_k) = (\alpha,\beta)$, and $f:\mathbb{C}^n \mapsto  \mathbb{C}$; and is undefined otherwise, and,
%\item $\ttype(\ffor{v}{X}{e}) = \ttype(e)$, if $\ttype(X) = \ttype(e)$, and $\ttype(v) = (\gamma,1)$; and is undefined otherwise.
%\end{itemize}
%\cristian{Is this the same than in the previous section? Is there any difference?}
% To extend \lang\, we add $\ffor{v}{X}{e}$ construct, which allows looping over the canonical vectors of a specified dimension, and updating the context of the variable $X$ in each iteration. The latter operator is i
%
% A \langfor {\em schema} $\Sch$ is a pair $\Sch=(\Mnam,\size)$, where $\Mnam\subset \Mvar$ is a finite set of matrix variables, and $\size: \Mvar \mapsto \DD\times \DD$ is a function that maps each matrix variable to a pair of {\em size symbols}. 
We also remark that in the definition of the type of $\ffor{v}{X}{e}$, we require that $\ttype(X) = \ttype(e)$ as this expression updates the content of the variable $X$ in each iteration using the result of $e$. We further restrict the type of 
$v$ to be a vector, i.e., $\ttype(v)=(\gamma,1)$, since $v$ will be instantiated with canonical vectors.
% As we will see below, evaluating $e$ will depend on a canonical vector stored in $v$, and the current content of $X$. %Another difference from \lang\ is that we allow function application only on scalars (more precisely, on $1\times 1$ matrices).
%
A \langfor\ expression $e$ is well-typed over a schema $\Sch$ if its type is defined. 

For well-typed expressions we next define their semantics. This is done in an inductive way, just as for \lang. To define the semantics of $\ffor{v}{X}{e}$ over an instance $\I$, we need the following notation. Let $\I$ be an instance and $V\in \Mnam$. Then $\I[V := A]$ denotes an instance that coincides with $\I$, except that the value of the matrix variable $V$ is given by the matrix $A$. Assume that
$\ttype(v)= (\gamma,1)$, and $\ttype(e) = (\alpha,\beta)$ and $n := \dom(\gamma)$. Then, $\sem{\ffor{v}{X}{e}}{\I}$ is defined iteratively, as follows:
\begin{itemize}
\item Let $A_0 := \mathbf{0}$ be the zero matrix of size $\dom(\alpha)\times \dom(\beta)$.
\item For $i=1,\ldots n$, compute $A_i:= \sem{e}{\I[v := b^{n}_i, X:= A_{i-1}]}$.
\item Finally, set $\sem{\ffor{v}{X}{e}}{\I}:= A_{n}$.
\end{itemize}

%%
% A \langfor {\em instance} $\I$ over a schema $\Sch$, is a pair $\I = (\dom,\conc)$, where $\dom : \DD \mapsto \mathbb{N}$ assigns a value to each size symbol, and $\conc : \Mnam \mapsto \mtr{\mathbb{C}}$ assigns a concrete matrix to each matrix variable $M\in \Mnam$, such that $\dim(\conc(M)) = \dom(\alpha)\times \dom(\beta)$, where $\size(M) = (\alpha,\beta)$. As before, we assume that $\dom(1) = 1$, for every instance $\I$.
%  %(meaning that $e_1^n = \begin{bmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{bmatrix}$, etc.).
% If $\I$ is an instance, $V$ a matrix variable such that $\size(V)= (\alpha,\beta)$, and $M$ a matrix of dimension $\dom(\alpha)\times \dom(\beta)$, then $\I[V := M]$ denotes an instance that coincides with $\I$, apart from the fact that the value of the matrix variable $V$ is the matrix $M$.
% %If $e$ is a well-typed expression according to $\Sch$, then we denote by $\sem{e}{\I}$ the matrix obtained by evaluating $e$ over $\I$, and define it as follows:
% %\begin{itemize}
% %\item $\sem{M}{\I} = \conc(M)$, for $M\in \Mnam$;
% %\item $\sem{e^*}{\I} = \sem{e}{\I}^*$, where $M^*$ is the conjugate transpose of a matrix $M$;
% %\item $\sem{e_1\cdot e_2}{\I} = \sem{e_1}{\I} \cdot \sem{e_2}{\I}$;
% %\item $\sem{e_1 + e_2}{\I} = \sem{e_1}{\I} + \sem{e_2}{\I}$;
% %\item $\sem{f(e_1,\ldots ,e_n)}{\I}$ is a $1\times 1$ matrix whose only entry has the value $f(\sem{e_1}{\I},\ldots ,\sem{e_n}{\I})$. Here we abuse the notation and use $\sem{e}{\I}$ to denote both a $1\times 1$ matrix, and a scalar from $\mathbb{C}$.
% %\item $\sem{f(e_1,\ldots ,e_n)}{\I}$ is a matrix $A$ of the same size as $\sem{e_1}{\I}$, and where $A_{ij}$ has the value $f(\sem{e_1}{\I}_{ij},\ldots ,\sem{e_n}{\I}_{ij})$.
% %\end{itemize}
% %\cristian{The same as with the type function, we can reuse the semantics of the previous section.}
%
% If $e$ is a well-typed expression according to $\Sch$, then we denote by $\sem{e}{\I}$ the matrix obtained by evaluating $e$ over $\I$, and define it as in \lang\, adding the new operator.
% \floris{Perhaps it is insightful to already give an easy example here, e.g., clique. Perhaps even better are the very simple expressions for diag and one vector. The text below is quite
% cryptic.}
%
% Notice that evaluating $\ffor{v}{X}{e}$ over an instance that already assigns values to $v$ and $X$, these values get overwritten immediately. Notice that if $e$ does not use the variable $v$, then it will have the same value in each iteration. Sometimes when we want to make it explicit that the expression $e$ uses matrix variables $X_1,\ldots ,X_n$, we write $e(X_1,\ldots ,X_n)$, where $X_1,\ldots ,X_n$ are all the matrix variables mentioned in $e$. Analogously with First Order Logic, we could define the notion of free and bound variables (i.e. the ones in the scope of a \texttt{for} operator), however, since we explicitly rewrite the value of these variables, this distinction will not play an important role.
%
%
% \cristian{I don't understand this comment of free and bound variables. What do you mean? I believe than similar than in first order variables, one can define this concept, but here it is not used.}
%
% %\subsection{Examples of \langfor expressions}




%%needs dimensions:
%Next we illustrate the versatility of the introduced language. To begin, we note that, unlike the original \lang\ proposal, we have at our disposals canonical vectors of arbitrary dimension. The most basic use of canonical vectors is for accessing a position $ij$ of some matrix $M$, a property which lies outside of the scope of \lang. For this, we can simply use the expression $(e_i^{n})^*\cdot M \cdot e_j^m$, where $M$ is a matrix of size $m\times n$, $e_i^n$ is the $i$th canonical vector of dimension $n$, and likewise, $e_j^m$ is the $j$th canonical vector of dimension $m$.

For better understanding how \langfor  works, we next provide some  examples.
We start by showing that the one-vector and $\diag$ operators are redundant
in \langfor.
% next present a series of properties that the language can express and introduce some operators that will be commonly used throughout the paper.
% , and show how the proposed language captures original \lang.
\begin{example}\label{ex:onevec}
We first show how the one-vector operator $\ones(e)$ can be expressed using \texttt{for} loops.
It suffices to consider the expression
$$e_{\ones}:=\ffor{v}{X}{X+v},$$
with $\ttype(v)=(\alpha,1)=\ttype(X)$ if $\ttype(e)=(\alpha,\beta)$. This expression is well-typed
and is of type $(\alpha,1)$. When evaluated over some instance $\I$ with $n=\dom(\alpha)$, $\sem{e_{\ones}}{\I}$ is defined as follows.
Initially, $A_0:=\mathbf{0}$. Then $A_i:=A_{i-1}+b_i^n$, i.e., the $i$th canonical vector is added to $A_{i-1}$.
Finally, $\sem{e_{\ones}}{\I}:=A_n$ and this now clearly coincides with $\sem{\ones(e)}{\I}$.\qed
\end{example}

% \begin{example}\label{ex:forml-identity}
% We first show how one can construct the identity matrix of a certain dimension. For this, it suffices to use the expression $$e_{\mathsf{Id}}:=\ffor{v}{X}{X + v\cdot v^T}.$$ For this expression to be well-typed, $v$ has to be a vector variable of type $\alpha\times 1$ and $X$ a matrix variable of type $(\alpha,\alpha)$. When evaluated over some instance $\I$, this loop starts by initializing $X$ as the zero matrix of dimension $n\times n$, where $n=\dom(\alpha)$, and then adds to $X$ the matrix $b_1^n\cdot (b_1^n)^T$ in the first iteration, the matrix $b_2^n\cdot (b_2^n)^T$ in the second iteration, and so on, until finally $b_n^n\cdot (b_n^n)^T$ is added. Hence, $X$ equals the identity matrix of dimension $n\times n$ in the end.\qed
% \end{example}
%
\begin{example}\label{ex:diag}
% Indeed, a minor variation of the expression $e_{\mathsf{Id}}$ suffices:
% As another example, we
We next show that the $\diag$ operator is redundant in \langfor.
Indeed, it suffices to consider the expression
$$e_{\mathsf{diag}}:=
\ffor{v}{X}{X + (v^T\cdot e) \times v\cdot v^T},$$ where $e$ is a \langfor\  expression of type $(\alpha,1)$. For this expression to be well-typed, $v$ has to be a vector variable of type $\alpha\times 1$ and $X$ a matrix variable of type $(\alpha,\alpha)$. Then, $\sem{e_{\mathsf{diag}}}{\I}$ is defined as follows.
Initially, $A_0$ is the zero matrix of dimension $n\times n$, where $n=\dom(\alpha)$. Then, in each iteration
$i\in[1..n]$, $A_{i}:=A_{i-1}+  ((b_i^n)^T\cdot\sem{e}{\I})\times (b_i^n\cdot (b_i^n)^T)$. In other words, $A_i$ is obtained by adding the matrix with value $(\sem{e}{\I})_i$ on position $(i,i)$ to $A_{i-1}$. Hence, $\sem{e_{\mathsf{diag}}}{\I}:=A_n=\sem{\diag(e)}{\I}$.\qed
%  and
% thus we get that $\sem{e_{\mathsf{diag}}}{\I}=\sem{\diag(e)}{\I}$.\qed%
 \end{example}
% That is, $A_i$ is obtained from $A_{i-1}$the $i$th entry of
% $\sem{e}{\I})^T$ is multiplied
%
% The difference with $e_{\mathsf{Id}}$ is that instead of the value $1$, the value
% $b_i^T\cdot\sem{e}{\I}=\sem{e}{\I}_{i}$ is put on position $i$ on the diagonal, when evaluating $e_{\mathsf{diag}}$ on $\I$.
%  One can verify that for the above expression to be well-typed, $v$ needs to be of type $(\alpha,1)$ and $X$ of type $(\alpha,\alpha)$. When evaluated over some instance $\I$, $X$ is initialised with the zero matrix of dimension $n\times n$, where $n=\dom(\alpha)$. Then, in iteration $i$, the $n\times n$-matrix
% $b_i^T\cdot \sem{e}{\I}\times (b_i\cdot b_i^T)$ is added. In other words, on the $i$th element of the diagonal, represented by $b_i\cdot b_i^T$, the value $b_i^T\cdot\sem{e}{\I}=\sem{e}{\I}_{i}$ is added. 
% That is, the expression $e_{\mathsf{diag}}$ evaluates to $\sem{\diag(e)}{\I}$.\qed

% It is also readily verified that the one-vector operator in \lang\ becomes redundant in \langfor.

%\floris{I commented out the part related to function applications, i.e., that function applications on scalars is sufficient. It is interesting but may be too much at this point? }

% Furthermore, general function applications can be simulated in \langfor\ by just assuming function applications $f(e_1,\ldots,e_k)$ for $f\in\Fun_k$ where $\ttype(e_i)=(1,1)$ for all $i\in[k]$, as is illustrated next.
% As before, we write \langfor$(\Fun)$ when \langfor\ expressions require certain function applications in some set $\Fun$.
%
% \begin{example}Consider the \langfor$(f)$ expression
% \begin{multline*}
% e=\texttt{for }v,X.\, X + \\
% \texttt{for }w,Y.\, Y + v\cdot f(v^T\cdot e_1\cdot w, \ldots, v^T\cdot e_k\cdot w)\cdot w^T.
% \end{multline*}
% In the expression above, we basically loop over all positions in $\sem{e_i}{\I}$, one by one, and apply the function $f$ on those positions.  One can see that $\sem{e}{\I}=\sem{f(e_1,\ldots,e_k)}{\I}$ for $e_i$'s of arbitrary type, but that $f$ is only
% applied on expressions of type $(1,1)$, such as $v^T\cdot e_i\cdot w$. \qed
% \end{example}
% %
%
% \smallskip
% \noindent
% \textbf{Core operators}. The previous example show that we can define \langfor\ using a small number of core operators, whilst still extending \lang. In particular, it suffices to define \langfor to consist of expressions of the form
% %
% %
% %
% % Note that the  \texttt{for} operator is much more powerful that it seems. We can simulate some operations of the original \lang\ semantics. Assume the allowed expressions are
%
% \begin{tabular}{lcll}
% $e$ & $:=$ & $V\in \Mvar$ & (matrix variable)\\
%  % & $|$ & $e^T$ & (transpose)\\
%  & $|$ & $e_1 \cdot e_2$ & (matrix multiplication)\\
%  % & $|$ & $e_1 + e_2$ & (matrix addition)\\
%  & $|$ & $\text{apply}[f](e_1,\ldots ,e_k)$ & (application of $f\in \Fun$)\\
%  & $|$ & $\ffor{v}{X}{e}$ & (canonical for loop, with $v, X \in \Mvar$).
% \end{tabular}
%
% Where function application $\text{apply}[f]$ works only on scalars. This is
%
% \begin{itemize}
% \item $\ttype(\text{apply}[f](e_1,\ldots ,e_n)) = (1,1)$, whenever $\ttype(e_1)= \cdots =\ttype(e_n)=(1,1)$, and $f:\mathbb{C}^n\mapsto \mathbb{C}$; and is undefined otherwise.
% \item $\sem{\text{apply}[f](e_1,\ldots ,e_n)}{\I}$ is a $1\times 1$ matrix whose only entry has the value $f(\sem{e_1}{\I},\ldots ,\sem{e_n}{\I})$.
% \end{itemize}

These examples illustrate that we can limit \langfor to consist of the following ``core'' operators: transposition, matrix multiplication and addition, scalar multiplication, pointwise function application, and for-loops. More specific, \langfor is defined by the following simplified syntax:
$$
e ::= V \ \mid \ e^T \!\ \mid \ e_1 \cdot e_2 \ \mid \ e_1 + e_2 \ \mid \ e_1\times e_2  \ \mid \  f(e_1,\ldots ,e_k) \ \mid \ \ffor{v}{X}{e}
$$
Similarly as for \lang, we write $\langforf{\Fun}$ for some set $\Fun$ of functions when these are required for the task at hand.

%  $f(e_1,\ldots,e_k)$ for $f\in\Fun_k$ where each $e_i$
% has type $(1,1)$.

%As a final example, we show how the Floyd-Warshall algorithm for computing the transitive closure of a matrix given in the Introduction can be defined using \langfor.
%\begin{example}\label{ex:floyd}
%The following expression in $\langf{f_>}$ computes the transitive closure of a $n\times n$ matrix $A$.
%\begin{tabbing}
%\texttt{for }\=$e_k,X_1.\, X_1 + $\\
%\> \texttt{for }\=$e_i,X_2.\, X_2 +$ \\
%\>\>\texttt{for }\=$e_j,X_3.\, X_3 +$ \\
%\>\>\>$(e_i^T\cdot A\cdot e_k \cdot e_k^T\cdot A\cdot e_j)\times e_i\cdot e_j^T$
%\end{tabbing}
%\end{example}


As a final example, we show that we can compute whether a graph contains a 4-$\textsf{clique}$ using \langfor.
\begin{example}\label{ex:fourcliques}
To test for $4$-cliques it suffices to consider the following expression with for-loops nested four times:
\begin{tabbing}
\texttt{for\,}\=$u,\,X_1.\ \ X_1 \ + $\\
\> \texttt{for\,}\=$v,\,X_2.\ \ X_2 \ +$ \\
\>\>\texttt{for\,}\=$w,\,X_3.\ \ X_3 \ +$ \\
\>\>\>\texttt{for\,}\=$x,\,X_4.\ \ X_4 \ +$ \\
\>\>\>\>$u^T\cdot V\cdot v \cdot u^T\cdot V\cdot w\cdot u^T\cdot V\cdot x \cdot $\\
\>\>\>\>$v^T\cdot V\cdot w \cdot v^T\cdot V\cdot x\cdot w^T\cdot V\cdot x \cdot g(u,v,w,x)$
\end{tabbing}
with $g(u,v,w,x)=f(u,v)\cdot f(u,w)\cdot f(u,x)\cdot f(v,w)\cdot f(v,x)\cdot f(w,x)$ and
$f(u,v)=1-u^T\cdot v$. Note that $f(b_i^n,b_j^n)=1$ if $i\neq j$ and $f(b_i^n,b_j^n)=0$ otherwise.
Hence, $g(b_i^n,b_j^n,b_k^n,b_\ell^n)=1$ if and only if all $i,j,k,l$ are pairwise different.
When evaluating the expression on an instance $\I$ such that $V$ is assigned to the adjacency 
matrix of a graph, the expression above evaluates to a non-zero value if and only if the graph
contains a four-clique.\qed
\end{example}
%
% % =\begin{cases}
% %                0 \text{ if } u=v \\
% %                1 \text{ if } u\neq v
% %             \end{cases}
% % 		\]
%
% To distinguish four-cliques, we will need to determine whether we are dealing with four different nodes. For this, we will utilize the function $$g(u,v,w,r)=f(u,v)\cdot f(u,w)\cdot f(u,r)\cdot f(v,w)\cdot f(v,r)\cdot f(w,r),$$

% As mentioned previously, g
Given that \lang can not check for 4-cliques \cite{matlang-journal}, we easily obtain the following.

\begin{proposition}
\label{cor-ml-fml}
For any collection of functions $\Fun$, 
$\langf{\Fun}$ is properly subsumed by $\langforf{\Fun}$.
\end{proposition} 







%\domagoj{This is used to simulate circuits, so I put in into a lemma. Perhaps just move to the appendix before that particular proof.}
%
%Another interesting consequence of allowing for loops in \lang\ is that the pointwise product and sum can be defined without direct access to these operators. Namely, the following result tells us that we can always assume to have access to the product and the sum.
%%This will be of crucial importance when comparing \langfor\ to arithmetic circuits in Section \ref{sec:circuits} and to annotated relations in Section \ref{sec:restrict}. Formally, we have:
%
%\begin{lemma}
%\label{lm-prod-sum}
%Let $f_\odot^k:\RR^k\mapsto \RR$ and $f_\oplus^k:\RR^k\mapsto \RR$ be the product and the sum function with $k$ attributes, respectively. Then it holds that $\langforf{\emptyset} \equiv \langforf{\{f_\odot^k,f_\oplus^k \ | \ k\in \mathbf{N}\}}$.
%\end{lemma}
%\cristian{This result is very ugly, why we want this? The interesting result is that you only need the function between constants to define the point-wise application of functions.}
%
%In what follows, we will sometimes abuse the notation and write $\langfor$ both when we are talking about $\langfor(\emptyset)$, and when referring to the language in general. On the other hand, when stating formal results, we will always make the set of functions explicit, and will use $\langfor$ to denote $\langfor(\emptyset)$.

\subsection{Design decisions behind \langfor}

\input{./sections/design}

%\subsection{Loop Initialization} As the reader may have observed, in the semantics of \texttt{for} loops we 
%always initialise $A_0$ to the zero matrix $\mathbf{0}$ (of appropriate dimensions). It is often convenient
%to start the iteration given some concrete matrix  originating from the result of evaluation a \langfor\ expression $e_0$. To make this explicit, we write $\initf{e_0}{v}{X}{e}$ and its semantics is defined as above
%with the difference that $A_0:=\sem{e_0}{\I}$. We observe, however, that $\initf{e_0}{v}{X}{e}$ can already
%be expressed in \langfor. In other words, we do not loose generality by assuming an initialisation of $A_0$ by $\mathbf{0}$.
%The key insight is that in \langfor\ we can check during evaluation whether or not
%the current canonical vector $b_i^n$ is equal to the $b_1^n$. This is not entirely trivial to see and is due to fact that \texttt{for} loops iterate over the canonical vectors in a fixed order. We discuss this more in the next section. In particular, we can define a \langfor expression $\mmin$, which when evaluated on an instance, returns $1$ if its input vector is $b_1^n$, and returns $0$ otherwise. Given $\mmin$, consider now the
%\langfor\ expression
% $$\ffor{v}{X}{\mmin{v}\cdot e(v,X/e_0) + (1-\mmin{v})\cdot e(v,X)},$$
% where we explicitly list $v$ and $X$ as matrix variables on which $e$ potentially depends on, and where
% $e(v,X/e_0)$ denotes the expression obtained by replacing every occurrence of $X$ in $e$ with $e_0$.
%%
%%  As mentioned previously, all of the iterations in \texttt{for} loops start by initializing $A_0$ to the null matrix. We have already seen that this property is useful for defining the extremal points of our ordering, however, sometimes we would like to start the iteration using some concrete matrix $B$. Using the operator $\mmin$, we can actually achieve this as follows. First, let $\ffor{v}{X}{e(v,X)}$ be the \texttt{for} loop that begins iterating from the null matrix. Here we write $e(v,X)$ to denote the variables that $e$ potentially (but not necessarily) uses. To start the iteration from $B$ it now suffices to use the following loop:
%% $$\ffor{v}{X}{\mmin{v}\cdot e(v,X/B) + (1-\mmin{v})\cdot e(v,X)} \quad (\dag),$$
%% where $e(v,X/B)$ denotes the expression obtained by replacing every occurrence of $X$ in $e$ with $B$.
%When evaluating this expression on an instance $\I$, $A_0$ is initial set to the zero matrix, in the first iteration (when  $v=b_1^n$ and thus $\mmin{v}=1$)
%we have $A_1=\sem{e}{\I[v:=b_1^n,X:=\sem{e_0}{\I}]}$, and for consecutive iterations (when only the part related to $1-\mmin{v}$ applies) $A_i$ is updated as before. Clearly, the result of this evaluation is equal to
%$\sem{\initf{e_0}{v}{X}{e}}{\I}$. 
%
%As an illustration, we consider the transitive closure program from the beginning of this section. Similarly as for \lang, we write \langfor$(\Fun)$ for some set $\Fun$ of functions when these are required for the task at hand.
%%As an illustration, we consider the transitive closure program from the beginning of this section. Similarly as for \lang, we write \langfor$(\Fun)$ for some set $\Fun$ of functions when these are required for the task at hand. Analogously, we write $\langfor$ to denote $\langfor(\emptyset)$, but we might abuse the notation and write $\langfor$ to refer to the language in general.
%\begin{example}
% We can express transitive closure in \langfor$(f_>)$. Indeed, consider the expression 
%$$
%f_{>0}\left(\initf{e_{\mathsf{Id}}}{v}{X}{X\cdot (e_{\mathsf{Id}}+V)}\right),
%$$
%where $e_{\mathsf{Id}}$ is a \langfor\ expression constructing the identity matrix $I$. The expression $e_{\mathsf{Id}}$
%is just like the expression $e_{\mathsf{diag}}$ in Example~\ref{ex:diag}, but now only puts value $1$ on the diagonal.
% Observe that we start the loop using an initialisation by $I$. Hence, when evaluated on an instance $\I$ such that $V$ is an adjacency matrix $A$ of a graph, the expression above simply computes $(I+A)^n$, followed by the pointwise function application $f_{>0}$. In other words, it returns the adjacency matrix of the transitive closure of graph.\qed
%\end{example}
% \smallskip
% \noindent
% \textbf{More examples}. We conclude by showing that the two examples at the beginning of this section can be
% expressed in \langfor. Indeed, for $4\mathsf{clique}$ it suffices to consider
%
% The modified \texttt{for} expression will now use $B$ as the assignment of $X$ in the very first iteration (as determined by $\mmin{v}$), and will proceed as before whenever $v$ is not equal to the first canonical vector, thus defining the desired result. Since starting iteration with a non null matrix is often useful, we will denote  by $\initf{B}{v}{X}{e}$ the expression $(\dag)$.

% \noindent{\bf For loops.}
% The biggest novelty of $\langfor$ is the for operator. To illustrate how this operator can be used, we first show how one can construct the identity matrix of needed dimension in \langfor.

%%NOT DOABLE IF NO ACCESS TO DIMENSION
%\noindent{\bf Elementary matrix operations.} Here we show the true value of adding canonical vectors to the language, by illustrating how they allow us to express elementary matrix operations \cite{linalg}:
%\begin{enumerate}
%\item {\bf Row switching.} To switch the row $i$ and row $j$ of an $m\times n$ matrix $M$, we can simply use the expression $T^{ij} \cdot M$, where:
%$$T^{ij} = I^m - e_i^m\cdot (e_i^m)^* - e_j^m\cdot (e_j^m)^* + e_i^m\cdot (e_j^m)^* + e_j^m\cdot (e_i^m)^*.$$
%\item {\bf Row multiplication.} Multiplying a row by a scalar $c$ is performed by 
%\item {\bf Row addition.}
%\end{enumerate}
%Analogously, we can perform these transformations of columns, by using the transposed matrix $M^*$, and the canonical vectors of appropriate dimension.

% To begin with, consider the expression $$v_{max} := \ffor{v}{X}{v}.$$
% we can easily obtain the last canonical vector using the expression
% \medskip
%
% \noindent{\bf Core operators}
% Note that the  \texttt{for} operator is much more powerful that it seems. We can simulate some operations of the original \lang\ semantics. Assume the allowed expressions are
%
% \begin{tabular}{lcll}
% $e$ & $:=$ & $V\in \Mvar$ & (matrix variable)\\
%  & $|$ & $e^T$ & (transpose)\\
%  & $|$ & $e_1 \cdot e_2$ & (matrix multiplication)\\
%  & $|$ & $e_1 + e_2$ & (matrix addition)\\
%  & $|$ & $\text{apply}[f](e_1,\ldots ,e_n)$ & (application of $f\in \Fun$)\\
%  & $|$ & $\ffor{v}{X}{e}$ & (canonical for loop, with $v, X \in \Mvar$).
% \end{tabular}
%
% Where function application $\text{apply}[f]$ works only on scalars. This is
%
% \begin{itemize}
% \item $\ttype(\text{apply}[f](e_1,\ldots ,e_n)) = (1,1)$, whenever $\ttype(e_1)= \cdots =\ttype(e_n)=(1,1)$, and $f:\mathbb{C}^n\mapsto \mathbb{C}$; and is undefined otherwise.
% \item $\sem{\text{apply}[f](e_1,\ldots ,e_n)}{\I}$ is a $1\times 1$ matrix whose only entry has the value $f(\sem{e_1}{\I},\ldots ,\sem{e_n}{\I})$.
% \end{itemize}
%
% \subsection{Minimal Core}
% We have the following:
%
% \begin{itemize}
% \item {\em Pointwise function application.} Note that
%
% \begin{align*}
% f(e_1,\ldots, e_n)&=\\
% &\texttt{for }v,X.\quad X + \\
% &\quad \texttt{for }w,Y.\quad Y + \\
% &\quad \quad v\left[ \text{apply}[f](v^Te_1w, \ldots, v^Te_nw) \right] w^T
% \end{align*}
%
% \item {\em Conjugate transpose.} Let $\texttt{conj}(a) := \overline{a}$ be the conjugate function. Then we can simulate the conjugate transpose of expression $e$ as $\texttt{conj}(e^T)$.
% \item {\em One vector.} Using the function $f(x) := 1$, we can define $$\ones(e) := f(\texttt{for } v,X. X + e\cdot v).$$
% \item {\em Multiplying a matrix by a scalar.} Let $c$ be a scalar ($1\times 1$ matrix) and $f_{\times}(a, b) := a \times b$ . Then, for an expression $e$, $c\odot e := f_{\times}(\ones(e)\cdot c \cdot \ones(e^T)^T, e)$.
% \item {\em Diagonal of a vector.} The operator $\diag(e)$ can be defined as:
% $$\diag(e) := \texttt{for } v, X. X + (v^T\cdot e) \odot vv^T.$$
% \end{itemize}
%
% \section{Order!!}
%
% \noindent{\bf Order.} The \texttt{for} operator assumes that canonical vectors come in some particular order, however, it does not give us an immediate access to this order. An interesting question is whether, using the \texttt{for} loops, we can define a \langfor expression which allow us to define the order of canonical vectors. Next we show that this is indeed possible. To begin with, we can easily obtain the last canonical vector using the expression $$v_{max} := \ffor{v}{X}{v}$$
%
% The fundamental property of iteration we use here is that the result variable is always initiated with the null matrix. Therefore the loop above will simply keep on storing the current canonical vector before returning the final one. The ability to do this sort of manipulation was one of the reasons why we initiate $A_0$ in the semantics of \texttt{for} to null matrix.
%
% To define an order relation for canonical vectors, notice that the following matrix:
% \[
% Z_{eq} = \begin{bmatrix}
%     1 & 1 & \cdots &  1 \\
%     0 & \ddots & \ddots & \vdots \\
%     \hdotsfor{3} & 1 \\
%     0 & \cdots & \cdots & 1
% \end{bmatrix},
% \]
% has the property that $e_i^*\cdot Z_{eq} \cdot e_j$, for two canonical vectors $e_i,e_j$ of the same dimension, is equal to one if and only $i\leq j$, and is zero otherwise. $Z_{eq}$ can easily de defined in \langfor as follows:
% $$Z_{\text{eq}}=\ffor{v}{X}{X + \left[ (Xv_{max}) + v \right]v^* + vv^*_{max}},$$
% where $v_{max}$ is as defined above. The intuition behind this expression is that using the last canonical vector $v_{max}$, we have access to the final column of $X$ (via the product $X\cdot v_{max}$), to which we add the current canonical vector $v$, thus constructing $Z_{eq}$ by filling it column by column. By defining $$\lleq{u}{v} := u^*\cdot Z_{eq} \cdot v,$$
% we obtain an order relation that allows us to discern whether one canonical vector comes before the other in the order given by \texttt{for}. If we want a strict order, we can just use $Z_< := Z_{eq} - I$.
%
% Interestingly, we can also define the predecessor relation between canonical vectors. For this, we require the following matrix:
% %\[
% %S := \begin{bmatrix}
% %    0 & 1         & 0         & \cdots &  0 \\
% %    0 & \ddots & 1         & \cdots & 0 \\
% %    \vdots & \vdots & \ddots & \ddots & \vdots \\
% %    \hdotsfor{3} & \ddots & 1 \\
% %    0 & \cdots & \cdots & \cdots & 0
% %\end{bmatrix}.
% %\]
% \[
% S = \begin{bmatrix}
%     0 & 1 & \cdots &  0 \\
%     0 & \ddots & \ddots & \vdots \\
%     \hdotsfor{3} & 1 \\
%     0 & \cdots & \cdots & 0
% \end{bmatrix},
% \]
% Using this matrix, we have that for a canonical vector $e_i$:
% \[
%   			S\cdot e_i=\begin{cases}
%                e_{i-1}, \text{ if } i > 1 \\
%               \mathbf{0}, \text{ if } i = 1
%             \end{cases}
% 		\]
% where $\mathbf{0}$ is a vector of zeros of the same type as $e_i$. Notice also that $\ones(v)^*\cdot S \cdot v$ is equal to zero, for a canonical vector $v$, if and only if $v = e_1$ is the first canonical vector, and zero otherwise. To define the first canonical vector in the order given by \texttt{for}, we can then write:
% $$v_{min} := \ffor{v}{X}{\mmin{v}\cdot v},$$
% where the expression $\mmin{v}$ is defined as $\mmin{v} := 1 - \ones(v)^*\cdot S \cdot v$, and, when evaluated over canonical vectors, will result in $1$ if and only if $v=e_1$ is the first canonical vector. Finally, we denote that $S$ can be defined using the following \langfor expression:
% \begin{multline*}
% S:= \texttt{for }v,X.\quad X + \\
% \left[ (1 - v^*v_{max})vv_{max}^* - (Xv_{max}) v_{max}^* + (Xv_{max})v^*\right].
% \end{multline*}
%
%
%
%
