\section{Extended MATLANG}

\subsection{Adding canonical vectors to MATLANG}
One thing that we cannot do in MATLANG is to obtain a specific entry of a matrix. This entry is expected to be a $1\times 1$ matrix. We can do this by adding the standard unit vectors $e_j$ where 
\[
e_i=
\begin{bmatrix}
    0 \\
    \vdots \\
    1 \\
    \vdots \\
    0
\end{bmatrix}
\rightarrow i\text{-th position}
\]

We know show some examples of what can we express with this new feature. For ilustrative reasons, we asume that all the dimentions are well suited for the corresponding operation.

\begin{itemize}
	\item Get $A_{ij}$ with $e_i^*\cdot A\cdot e_j$.
	\item The expression $e_i\cdot e_j^*$ is the matrix that has a $1$ in the position $i,j$ and zero everywhere else.
	\item Given a vector $v$, the expression $v\cdot e_i^*$ is the matrix 
	\[
\begin{bmatrix}
    0 & \cdots & v_{1} & \cdots & 0 \\
    0 & \cdots & v_{2} & \cdots & 0 \\
    \hdotsfor{5} \\
    0 & \cdots & v_{n} & \cdots & 0 
\end{bmatrix}
\]
	\item Replace column $j$ of $A$ with zeros: $A(I-e_j\cdot e_j^*)$.
	\item Replace column $j$ of $A$ with a vector $v$: $A(I-e_j\cdot e_j^*) + v\cdot e_j^*$.
\end{itemize}

Note that $I=\text{diag}(\mathbf{1}(A))$ and the sum of matrices can be implemented as $\text{apply}\left[ + \right](A, B)$.

\subsection{Constant and variable expressions}

All the expressions so far are valid if they are composed of matrices that are on the instance $I$ (see section 1). Once you have an expression $E$ that is well defined on the given instance, it doesn't change its value unless the current instance is modified. We call this a \textit{constant} expression.

Now, let's turn our attention on the expressions $$E(v)=v^* Av.$$ The value of $E$ depends entirely on $v$, we call this a \textit{variable expression}. This type of expressions have \textit{free} variables ($v$ in this case) and it doesn't mean anything in MATLANG unless the \textit{free} variables are mapped into an actual matrix bye means of the $\ssum,\sprod$ operators.

\subsection{Syntax and semantics of  extMATLANG}

A vocabulary $\cS$ is a set of matrix names $\cM=M_1,\ldots, M_p$ and a set of vector names $X=x_1,\ldots, x_l$.
An instance $\cI$ is a function that maps matrix names to concrete matrices of a determined dimension $(m,n)$ and vector names to a determined dimension $(n, 1)$. 
We also assume the presence of $F$, a set of functions $f:\mathbb{R}^{k}\rightarrow\mathbb{R}$ (with $1\leq k$).

Let $\cS=(\cM, X)$ be a vocabulary, a formula in the vocabulary $\cS$ is of the form:
$$
E:= x\in X \ |\ M\in \cM \ |\  E^* \ |\ E_1+E_2 \ |\  E_1\cdot E_2 \ |\  f(E_1,\ldots, E_k), f\in F \ |\  \ssum x. E \ |\  \sprod x. E
$$

Now, given a vocabulary $\cS$, an instance $\cI$ and a set of functions $F$, we define the well typedness of a formula of $\cS$ according to $\cI$ as follows. 

\begin{align*}
\text{type}(x) &= (n,1) \text{ if } \cI(x) = (n, 1) \\
\text{type}(M) &= (n,m) \text{ if } \cI(M) \text{ is a } n\times m \text{ matrix } \\
\text{type}(E^*)&=(j,i) \text{ where } (i,j)=\text{type}(E) \\
\text{type}(E_1 + E_2) &= \text{type}(E_1) \text{ if } \text{type}(E_1)=\text{type}(E_2) \\
\text{type}(E_1\cdot E_2)&= (i,k) \text{ if } \text{type}(E_1)=(i,j)\text{ and type}(E_2)=(j,k) \\
\text{type}(f(E_1,\ldots, E_k))&=(1,1) \text{ if } \text{type}(E_1)=\cdots =\text{type}(E_k)=(1,1) \\
\text{type}\left(\ssum x.E\right) &= \text{type}(E) \\
\text{type}\left(\sprod x. E\right) &=
\begin{cases}
               (1,1) \text{ if } \text{type}(E)=(1,1) \\
               (n,n) \text{ if } \text{type}(E)=(n,n)
            \end{cases}
\end{align*}

We say that $E$ is well typed if it has a defined type. Now we will proceed with the semantics of these formulas.
First, we define $\text{type}(x)_1$ as the first coordinate of the type of $x$ and $\cI[x:= e^n_i]$ as the instance $\cI$ except that $x$ is mapped to the $i-$th canonical vector of size $n$.
Now, given $\cS, \cI, F$ and a well typed expression $E$, we define the semantics for the values $\sem{E}(\cS,\cI)$ inductively as follows.

\begin{align*}
\sem{M}(\cS,\cI)&=\cI (M) \\
\sem{E^*}(\cS,\cI)&=\sem{E}(\cS,\cI)^* \\
\sem{E_1+E_2}(\cS,\cI)&= \sem{E_1}(\cS,\cI)+\sem{E_2}(\cS,\cI)\\
\sem{E_1\cdot E_2}(\cS,\cI)&= \sem{E_1}(\cS,\cI)\times \sem{E_2}(\cS,\cI)\\
\sem{f(E_1,\ldots ,E_k)}(\cS,\cI) &= f\left(\sem{E_1}(\cS,\cI),\ldots , \sem{E_k}(\cS,\cI)\right)\\
\sem{\ssum x.E}(\cS,\cI)&= \sum_{i=1}^{n}\sem{E}(\cS,\cI[x:= e^n_i]),\text{ where }n=\text{type}(x)_1\\
\sem{\sprod x. E}(\cS,\cI)&= \prod_{i=1}^{n}\sem{E}(\cS,\cI[x:= e^n_i]),\text{ where }n=\text{type}(x)_1
\end{align*}

Here, $+$ is matrix sum, $\times$ is matrix multiplication and 
\begin{align*}
\sum_{i=1}^n E_i = E_1+\cdots + E_n \\
\prod_{i=1}^n E_i = E_1\times \cdots\times E_n
\end{align*}
Depending on context, we sometimes denote explicitly that an expression $E$ depends on $x$ as $E(x)$.

First, note that the definition of these operators is not ambiguous in taking column vectors instead of row vectors or doing the aggregate matrix multiplication by right, because row vectors are the canonical vectors as well, and transposing gives us one from the other. On the other hand, if you want the result of the aggregate multiplication to be computed in the inverse order, note that, since $(AB)^*=B^*A^*$ we have $$\sprod^{\text{left}} x.E(x)=\left(\sprod x.E(x)^*\right)^*.$$

On the other hand, expressions that depend on a variable $x$ can be well typed according to the typing rules, but we cannot infer a value (semantic) unless $x$ is instantiated by $\ssum$ or $\sprod$.

\subsection{Simulating MATLANG}

We will now show that we can simulate MATLANG operators in our extMATLANG language.

\subsubsection{Ones vector and diag()}

Note that $$\text{ones}(M)=\ssum x_1. f_1(\ssum x_2. x_1^*Mx_2)\cdot x_1.$$ And $$\text{diag}(v)=\ssum x. (x^*v)\cdot xx^*$$

\subsubsection{Identity}

Given a $n\times m$ matrix, we can compute the $n\times n$ identity as $$\ssum x. f_1\left(x^*MM^*x\right)\cdot x \cdot x^* = \text{ones}(M)\cdot\text{ones}(M)^*$$ and the $m\times m$ identity as $$\ssum x. f_1\left(x^*M^*Mx\right)\cdot x \cdot x^*= \text{ones}(M^*)\cdot\text{ones}(M^*)^*$$

\subsubsection{Matrix pointwise function application (apply[f])}

We have that 

\begin{itemize}
	\item \textbf{Pointwise application:} if $A^{(1)}, \ldots, A^{(n)}$ are $m\times p$ matrices, then apply$\left[ f \right](A^{(1)}, \ldots, A^{(n)})$ is the $m\times p$ matrix $C$ where $C_{ij}=f(A^{(1)}_{ij}, \ldots, A^{(n)}_{ij})$.
\end{itemize}

So, given the \textbf{sum} operator and the function $f$, we can compute $C$ in the following way: $$C=\ssum x_i.\ssum x_j. f\left( x_i^*A^{(1)}x_j, \cdots, x_i^*A^{(n)}v_j\right)\cdot x_ix_j^*$$

Recall that $v_iv_j^*$ is the matrix that has a 1 in the position i, j and zero everywhere else.

Thus, we can simulate the MATLANG operator apply[$f$].

For example, matrix pointwise multiplication: $$\ssum x_i.\ssum x_j.\left( x_i^*A^{(1)}x_j\times \cdots\times x_i^*A^{(n)}x_j\right)\cdot x_ix_j^*$$

\subsubsection{Matrix multiplication via sum operator}

Note that using the sum operator we can compute matrix multiplication by definition $$A\cdot B = \ssum x_i\ssum x_j\ssum x_k \left( x_iAx_k\cdot x_kBx_j\right)x_ix_j^*$$

\subsection{Examples}

Let's see some examples of what we can do with extMATLANG.

\subsubsection{Trace and diagonal product}

We can express $$tr(A)=\ssum x. x^*Ax.$$

And the product of the diagonal of a matrix (this can be useful in computing the determinant of an upper/down triangular matrix): $$dp(A)=\sprod x. x^*Ax.$$

\subsubsection{Transitive closure}

To compute transitive closure we need the quantity $(A+I)^n$ and use apply[$f>0$] on the result matrix. Then we have that $$(I+A)^n=\sprod v. (I+A),$$ and thus $$TC = \text{apply}\left[ f_{>0}\right]\left( \sprod v. (I+A) \right).$$
Using only the new operators, we have that $$TC=\ssum v_i. \ssum v_j. f_{>0}\left(v_i^*\left(\sprod v. (I+A)\right)v_j\right)$$

\subsubsection{$k$-cliques}

Let's try to see first if there is a four clique in the adjacency matrix $A$. To do this, we need to verify if there are paths between four \textbf{different} nodes. So we need the function 

\[
  			f(u,v)=1-u^*v=\begin{cases}
               0 \text{ if } u=v \\
               1 \text{ if } u\neq v
            \end{cases}
		\]

Define $$g(u,v,w,r)=f(u,v)\cdot f(u,w)\cdot f(u,r)\cdot f(v,w)\cdot f(v,r)\cdot f(w,r).$$ This is, $g$ is zero if any pair of vectors are the same.
		
So $$\ssum v_1.\ssum v_2. \ssum v_3. \ssum v_4. (v_1^*Av_2)(v_1^*Av_3)(v_1^*Av_4)(v_2^*Av_3)(v_2^*Av_4)(v_3^*Av_4)g(v_1,v_2,v_3,v_4).$$

\label{sec:extmatlang}