\section{Extended MATLANG}

\subsection{Adding canonical vectors to MATLANG}
One thing that we cannot do in MATLANG is to obtain a specific entry of a matrix. This entry is expected to be a $1\times 1$ matrix. We can do this by adding the standard unit vectors $e_j$ where 
\[
e_i=
\begin{bmatrix}
    0 \\
    \vdots \\
    1 \\
    \vdots \\
    0
\end{bmatrix}
\rightarrow i\text{-th position}
\]

We know show some examples of what can we express with this new feature. For ilustrative reasons, we asume that all the dimentions are well suited for the corresponding operation.

\begin{itemize}
	\item Get $A_{ij}$ with $e_i^*\cdot A\cdot e_j$.
	\item The expression $e_i\cdot e_j^*$ is the matrix that has a $1$ in the position $i,j$ and zero everywhere else.
	\item Given a vector $v$, the expression $v\cdot e_i^*$ is the matrix 
	\[
\begin{bmatrix}
    0 & \cdots & v_{1} & \cdots & 0 \\
    0 & \cdots & v_{2} & \cdots & 0 \\
    \hdotsfor{5} \\
    0 & \cdots & v_{n} & \cdots & 0 
\end{bmatrix}
\]
	\item Replace column $j$ of $A$ with zeros: $A(I-e_j\cdot e_j^*)$.
	\item Replace column $j$ of $A$ with a vector $v$: $A(I-e_j\cdot e_j^*) + v\cdot e_j^*$.
\end{itemize}

Note that $I=\text{diag}(\mathbf{1}(A))$ and the sum of matrices can be implemented as $\text{apply}\left[ + \right](A, B)$.

\subsection{Constant and variable expressions}

All the expressions so far are valid if they are composed of matrices that are on the instance $I$ (see section 1). Once you have an expression $E$ that is well defined on the given instance, it doesn't change its value unless the current instance is modified. We call this a \textit{constant} expression.

Now, let's turn our attention on the expressions $$E(v)=v^* Av.$$ The value of $E$ depends entirely on $v$, we call this a \textit{variable expression}. This type of expressions have \textit{free} variables ($v$ in this case) and it doesn't mean anything in MATLANG unless the \textit{free} variables are mapped into an actual matrix of the current instance, we denote this $E(v)(I[v\rightarrow B])$, assuming that $B$ is on the domain of the given instance. This mapping will be accomplished trough operators that are introduced in the next section. These operators define how the variable expression $E$ is used and how it's instantiated.
A formal example, let $\lbrace v_i\rbrace_i$ be the canonical vectors. An operator could receive a variable expression $E(v)$ and give the output $E(v_k)=B$, if and only if $[E(v)](I[v\rightarrow v_k])=B$.
We now proceed to define the semantics of this formulas.

\subsection{Syntax and semantics of  extMATLANG}

A schema $\cS$ is a set of matrix names $M_1,\ldots, M_p$ and a set of vector names $v_1,\ldots, v_l$.
An instance $\cM$ is a function that maps matrix names to concrete matrices (of dimention $n\times n$) and vector names to concrete colun vectors (of dimention $n\times 1$). 
In addition, we define $dim(\cM)=n$ and $can(\cM)$ as the set of canonical vectors of dimention $n$, indexed as $can(\cM)[1], \ldots,can(\cM)[n]$.

Let $\cM$ be an intance and $n=dim(\cM)$. Let $V$ be a set of vector variables (matrix variables, respectively). A valuation $\nu$ on instance $\cM$ is a function from $X$ to column vectors of dimention $n\times 1$ (matrices of dimention $n\times n$, respectively). 

Let $\cS$ be an schema, $\cM$ an instance, $F$ a set of functions $f:\mathbb{R}^{k}\rightarrow\mathbb{R}$ (with $1\leq k$) and $V$ a set of vector variables. An \textit{extended} MATLANG expression $E$ is given by
$$
E:= \ |\  x\in V \ |\  M\in S \ |\  v\in S \ |\  E^* \ |\ E_1+E_2 \ |\  E_1\cdot E_2 \ |\  f(E_1,\ldots, E_k), f\in F \ |\  \sum x. E \ |\  \prod x. E \ |\ 
$$

Let $n=dim(\cM)$. We define $\text{type}(E)=(i,j)$ where $(i,j)\in \lbrace 1, n\rbrace$. The well typeness is defined recursively as follows.

\begin{align*}
\text{type}(x) &= (n,1) \\
\text{type}(M) &= (n,n) \\
\text{type}(v) &= (n,1) \\
\text{type}(E^*)&=(j,i) \text{ where } (i,j)=\text{type}(E) \\
\text{type}(E_1 + E_2) &= \begin{cases}
               \text{type}(E_1) \text{ if } \text{type}(E_1)=\text{type}(E_1) \\
               \text{undefined} \text{ otherwise }
            \end{cases} \\
\text{type}(E_1\cdot E_2)&=\begin{cases}
               (i,k) \text{ if } \text{type}(E_1)=(i,j)\text{ and type}(E_2)=(j,k) \\
               \text{undefined} \text{ otherwise }
            \end{cases} \\
\text{type}(f(E_1,\ldots, E_k))&=\begin{cases}
               (1,1) \text{ if } \text{type}(E_1)=\cdots =\text{type}(E_k)=(1,1) \\
               \text{undefined} \text{ otherwise }
            \end{cases} \\
\text{type}\left(\sum x.E\right) &= \text{type}(E) \\
\text{type}\left(\prod x. E\right) &=
\begin{cases}
               (1,1) \text{ if } \text{type}(E)=(1,1) \\
               (n,n) \text{ if } \text{type}(E)=(n,n) \\
               \text{undefined } \text{ otherwise }
            \end{cases}
\end{align*}
We say that $E$ is well typed if it has a defined type. Here, type(undefined)$=$ undefined.


Given $\cM, \nu, V$ and a well typed expression $E$, we define the semantics for the values $\left[ E\right](\cM,\nu)$ inductivelly as follows. 


\begin{align*}
\left[ x\right](\cM,\nu)&=\nu (x)\\
\left[ M\right](\cM,\nu)&=\cM (M) \\
\left[ v\right](\cM,\nu)&=\cM (v) \\
\left[ E^*\right](\cM,\nu)&=\left[ E\right](\cM,\nu)^* \\
\left[ E_1+E_2\right](\cM,\nu)&= \left[ E_1\right](\cM,\nu)+\left[ E_2\right](\cM,\nu)\\
\left[ E_1\cdot E_2\right](\cM,\nu)&= \left[ E_1\right](\cM,\nu)\times \left[ E_2\right](\cM,\nu)\\
\left[ f(E_1,\ldots ,E_k)\right](\cM,\nu) &= f\left(\left[ E_1\right](\cM,\nu),\ldots , \left[  E_k\right](\cM,\nu)\right)\\
\left[ \sum x.E\right](\cM,\nu)&= \sum_{i=1}^{dim(\cM)}\left[ E\right](\cM,\nu[x\rightarrow can(\cM)[i]])\\
\left[ \prod x. E\right](\cM,\nu)&= \prod_{i=1}^{dim(\cM)}\left[ E\right](\cM,\nu)[x\rightarrow can(\cM)[i]])
\end{align*}

Here, $+$ is matrix sum, $\times$ is matrix multiplication and 
\begin{align*}
\sum_{i=1}^n E_i = E_1+\cdots + E_n \\
\prod_{i=1}^n E_i = E_1\times \cdots\times E_n
\end{align*}
Depending on context, we sometimes denote explicitly that an expression $E$ depends on $x$ as $E(x)$.

First, note that the definition of these operators is not ambiguous in taking column vectors instead of row vectors or doing the aggregate matrix multiplication by right, because row vectors are the canonical vectors as well, and transposing gives us one from the other. On the other hand, if you want the result of the aggregate multiplication to be computed in the inverse order, note that, since $(AB)^*=B^*A^*$ we have $$\prod^{\text{left}} x.E(x)=\left(\prod x.E(x)^*\right)^*.$$

\subsection{Simulating MATLANG}

We will now show that we can simulate MATLANG operators in our extMATLANG language.

\subsubsection{Identity}

We can express the identity of dimention $dim(I)$ as $$\sum x. x\cdot x^*.$$

\subsubsection{Ones vector and diag()}

Note that $$\text{ones}(v)=\sum x. x$$ And $$\text{diag}(v)=\sum x. (x^*v)\cdot xx^*$$

\subsubsection{Matrix pointwise function application (apply[f])}

We have that 

\begin{itemize}
	\item \textbf{Pointwise application:} if $A^{(1)}, \ldots, A^{(n)}$ are $m\times p$ matrices, then apply$\left[ f \right](A^{(1)}, \ldots, A^{(n)})$ is the $m\times p$ matrix $C$ where $C_{ij}=f(A^{(1)}_{ij}, \ldots, A^{(n)}_{ij})$.
\end{itemize}

So, given the \textbf{sum} operator and the function $f$, we can compute $C$ in the following way: $$C=\sum x_i.\sum x_j. f\left( x_i^*A^{(1)}x_j, \cdots, x_i^*A^{(n)}v_j\right)\cdot x_ix_j^*$$

Recall that $v_iv_j^*$ is the matrix that has a 1 in the position i, j and zero everywhere else.

Thus, we can simulate the MATLANG operator apply[$f$].

For example, matrix pointwise multiplication: $$\sum x_i.\sum x_j.\left( x_i^*A^{(1)}x_j\times \cdots\times x_i^*A^{(n)}x_j\right)\cdot x_ix_j^*$$

\subsection{Examples}

Let's see some examples of what we can do with extMATLANG.

\subsubsection{Trace and diagonal product}

We can express $$tr(A)=\sum x. x^*Ax.$$

And the product of the diagonal of a matrix (this can be useful in computing the determinant of an upper/down triangular matrix): $$dp(A)=\prod x. x^*Ax.$$

\subsubsection{Transitive closure}

To compute transitive closure we need the quantity $(A+I)^n$ and use apply[$f>0$] on the result matrix. Then we have that $$(I+A)^n=\prod v. (I+A),$$ and thus $$TC = \text{apply}\left[ f_{>0}\right]\left( \prod v. (I+A) \right).$$
Using only the new operators, we have that $$TC=\sum v_i. \sum v_j. f_{>0}\left(v_i^*\left(\prod v. (I+A)\right)v_j\right)$$

\subsubsection{$k$-cliques}

Let's try to see first if there is a four clique in the adjacency matrix $A$. To do this, we need to verify if there are paths between four \textbf{different} nodes. So we need the function 

\[
  			f(u,v)=1-u^*v=\begin{cases}
               0 \text{ if } u=v \\
               1 \text{ if } u\neq v
            \end{cases}
		\]

Define $$g(u,v,w,r)=f(u,v)\cdot f(u,w)\cdot f(u,r)\cdot f(v,w)\cdot f(v,r)\cdot f(w,r).$$ This is, $g$ is zero if any pair of vectors are the same.
		
So $$\sum v_1.\sum v_2. \sum v_3. \sum v_4. (v_1^*Av_2)(v_1^*Av_3)(v_1^*Av_4)(v_2^*Av_3)(v_2^*Av_4)(v_3^*Av_4)g(v_1,v_2,v_3,v_4).$$

\label{sec:extmatlang}